# ðŸš€ Taller 6 â€“ Terraform + Docker

Este laboratorio implementa una arquitectura de datos utilizando *Terraform* para orquestar contenedores Docker. Se diseÃ±Ã³ la separaciÃ³n entre procesos de *IngenierÃ­a de Datos (ETL)* y procesos de *Ciencia de Datos (ML API)*.  

- Javier Azurdia
- Angel Castellanos
- Sara EcheverrÃ­a
- Diego Morales
- Enlace al repositorio: https://github.com/Diego2250/MLOps-Taller6
---

## ðŸ“Œ 1. DocumentaciÃ³n consultada
- [Terraform Docker Provider](https://registry.terraform.io/providers/kreuzwerker/docker/latest/docs)  
- [DocumentaciÃ³n oficial de Docker](https://docs.docker.com/)  

---

## ðŸ“Œ 2. Arquitectura de Datos

El sistema estÃ¡ compuesto por *dos contenedores*:

### ðŸ”¹ ETL â€“ IngenierÃ­a de Datos
- *Contenedor:* etl-pipeline  
- *Dockerfile:* Dockerfile.pipeline  
- *CÃ³digo:* pipeline.py  
- *FunciÃ³n:* 
  - Cargar dataset.
  - Limpiar y transformar datos.
  - Entrenar modelo (scikit-learn).
  - Guardar modelo entrenado como model.joblib en /data.

### ðŸ”¹ ML API â€“ Ciencia de Datos
- *Contenedor:* ml-api  
- *Dockerfile:* Dockerfile  
- *CÃ³digo:* src/pipeline/app.py con *FastAPI*.  
- *FunciÃ³n:* 
  - Cargar model.joblib desde volumen compartido.
  - Exponer endpoints:
    - GET / â†’ healthcheck.  
    - POST /predict â†’ recibe features en JSON y devuelve predicciÃ³n.

---

## ðŸ“Œ 3. Infraestructura como CÃ³digo (IaC)

La infraestructura se define en main.tf con el provider Docker.  
Ejemplo de despliegue:

```bash
terraform init
terraform apply -auto-approve
```

Esto crea automÃ¡ticamente:
	â€¢	Imagen + contenedor de ETL.
	â€¢	Imagen + contenedor de la API ML.
	â€¢	Volumen compartido para persistir el modelo.

â¸»

ðŸ“Œ 4. Compartir imÃ¡genes Docker sin Docker Hub

Para exportar e importar imÃ¡genes sin un registry:

# Guardar imagen en archivo tar
docker save -o ml_app.tar ml_app:latest
docker save -o etl_app.tar etl_app:latest

# Copiar archivo a otra mÃ¡quina y cargarlo
```bash
docker load -i ml_app.tar
docker load -i etl_app.tar
```


â¸»

ðŸ“Œ 5. Evidencias

Terraform apply

Captura del despliegue exitoso.

Contenedores creados

docker ps -a

API corriendo

Acceso a http://localhost:8080/docs

PredicciÃ³n de ejemplo

Request

POST /predict
{
  "sepal length (cm)": 5.1,
  "sepal width (cm)": 3.5,
  "petal length (cm)": 1.4,
  "petal width (cm)": 0.2
}

Response

{
  "prediction": 0
}


â¸»

ðŸ“Œ 6. Conclusiones
	1.	Infraestructura como CÃ³digo (IaC): permite levantar entornos reproducibles y portables con un solo comando (terraform apply).
	2.	SeparaciÃ³n de roles: se evidenciÃ³ la diferencia entre procesos de ETL y de API de predicciones, lo cual refleja arquitecturas reales en MLOps.
	3.	Portabilidad de modelos: el uso de volÃºmenes y exportaciÃ³n de imÃ¡genes (docker save/load) facilita compartir soluciones sin necesidad de un registry.
	4.	Escalabilidad: esta misma arquitectura puede ser llevada a Kubernetes o la nube para ambientes productivos.

â¸»

ðŸ“Œ 7. Estructura del repo

â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile          # ML API
â”‚   â”œâ”€â”€ Dockerfile.pipeline # ETL
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ model.joblib    # modelo entrenado
â”‚   â””â”€â”€ src/pipeline/
â”‚       â”œâ”€â”€ app.py          # FastAPI
â”‚       â””â”€â”€ pipeline.py     # Entrenamiento
â”œâ”€â”€ terraform/
â”‚   â””â”€â”€ main.tf
â””â”€â”€ README.md
